{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da681cd-2193-4eb6-b5d3-03d239bfae2e",
   "metadata": {},
   "source": [
    "# Task_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c55d2-5f0a-4054-848d-18ce0582bffb",
   "metadata": {},
   "source": [
    "### Iris Dataset\n",
    "* The Iris dataset is one of the most well-known and commonly used datasets in the field of machine learning and statistics.\n",
    "* In this article, we will explore the Iris dataset in deep and learn about its uses and applications.\n",
    "* The Iris dataset consists of 150 samples of iris flowers from three different species: Setosa, Versicolor, and Virginica.\n",
    "* Each sample includes four features: sepal length, sepal width, petal length, and petal width.\n",
    "* It was introduced by the British biologist and statistician Ronald Fisher in 1936 as an example of discriminant analysis.\n",
    "* The Iris dataset is often used as a beginner's dataset to understand classification and clustering algorithms in machine learning.\n",
    "* By using the features of the iris flowers, researchers and data scientists can classify each sample into one of the three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7191ef8-7c6a-4325-9859-dc6e6059585d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch_20newsgroups\n",
      "fetch_20newsgroups_vectorized\n",
      "fetch_california_housing\n",
      "fetch_covtype\n",
      "fetch_kddcup99\n",
      "fetch_lfw_pairs\n",
      "fetch_lfw_people\n",
      "fetch_olivetti_faces\n",
      "fetch_openml\n",
      "fetch_rcv1\n",
      "fetch_species_distributions\n",
      "load_breast_cancer\n",
      "load_diabetes\n",
      "load_digits\n",
      "load_files\n",
      "load_iris\n",
      "load_linnerud\n",
      "load_sample_image\n",
      "load_sample_images\n",
      "load_svmlight_file\n",
      "load_svmlight_files\n",
      "load_wine\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# List all dataset functions in sklearn.datasets\n",
    "dataset_list = [func for func in dir(datasets) if func.startswith(('load_', 'fetch_'))]\n",
    "\n",
    "# Print each dataset function on a new line\n",
    "for dataset in dataset_list:\n",
    "    print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f1499-c903-4943-babc-995a69bbe563",
   "metadata": {},
   "source": [
    "### Take Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1892187-349b-4792-b29e-f7fc78ccfff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "iris = load_iris()       # Load the Iris dataset\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd138abd-f3cf-4dc4-a047-989a5526e10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "  \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "iris = load_iris()       # Load the Iris dataset\n",
    "X = iris.data            # Independent Variables  (Features)\n",
    "y = iris.target          # Dependent Variables    (Target Lables)\n",
    "print(X)\n",
    "print(\"  \")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d21086-ab33-4ba5-a425-c6d5d0abfb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set trained\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"data set trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ddc87-c23f-4124-bd3e-57859b52a893",
   "metadata": {},
   "source": [
    "### import naive bays (GaussianNB ,bernoulliNB, MultinationalNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57e07c75-df35-443c-afd0-fb14b45c9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85ce07-b135-4cf0-b510-ff6a18bad160",
   "metadata": {},
   "source": [
    "### Predict Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3043ec5b-3a12-467c-b61f-03fc0b2ec537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "print(y_pred_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d0a28cd-d1a7-4c24-8c57-3f50754d782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "print(y_pred_bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e34a705a-9b7e-407c-a23a-4ebf8633fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 1 0 0 0 0 1 2 1 1 2 0 1 0 2 1 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "print(y_pred_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43590f8-befc-4fe1-9dc6-7b67f6b2ed65",
   "metadata": {},
   "source": [
    "### Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66fb96e-af16-4c5a-a025-97ef747c2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "print(f\"GaussianNB Accuracy: {accuracy_gnb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2c4c8b-4db2-4922-9350-da96740dafbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "print(f\"BernoulliNB Accuracy: {accuracy_bnb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c755e310-e6d2-49c3-9da2-0f70ae2560b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "print(f\"MultinomialNB Accuracy: {accuracy_mnb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d3824-bef7-4210-b2c1-9841176d9399",
   "metadata": {},
   "source": [
    "### Understanding Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c971958-9da4-4842-ae43-46865ff6faa6",
   "metadata": {},
   "source": [
    "### Understanding Theory & Formula\n",
    "#### 1. Na√Øve Bayes Theorem:\n",
    "\n",
    "P(A|B) = P(B|A) X P(A)/P(B)\n",
    "\n",
    "Where:\n",
    "-  P(A|B) is the probability of class A given evidence B.\n",
    "-  P(B|A) is the likelihood of evidence given class A.\n",
    "-  P(A) is the prior probability of class A.\n",
    "-  P(B) is the prior probability of evidence.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Gaussian Na√Øve Bayes (GaussianNB)\n",
    "- Assumes features are normally distributed.\n",
    "- Uses the Gaussian (Normal) Distribution Formula:\n",
    "\n",
    "P(x|C) = 1/‚àö{2*œÄ*ùúé^2} e^-{(x - Œº)^2/2ùúé^2}\n",
    "\n",
    "Where:\n",
    "\n",
    "- Œº = Mean of the feature.\n",
    "- ùúé^2  = Variance of the feature.\n",
    "  \n",
    "---\n",
    "\n",
    "### 3. Bernoulli Na√Øve Bayes (BernoulliNB)\n",
    "- Used for binary (0/1) features.\n",
    "- Probability formula:\n",
    "\n",
    "P(x|C) = p^x (1 - p)^(1 - x)\n",
    "\n",
    "\n",
    "Where:\n",
    "- p  = Probability of feature being 1.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Multinomial Na√Øve Bayes (MultinomialNB)\n",
    "- Used for text classification (counts of words).\n",
    "- Formula:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P(x|C) = (N_C)!/(x_1!.x_2!.  ... x_n!) prod_{i=1}^{n} P(w_i|C)^x_i\n",
    "    \n",
    "\n",
    "Where:\n",
    "- P(w_i|C) is the probability of word w_i in class C.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Manual Calculations (By Hand)\n",
    "To implement by hand:\n",
    "1. Calculate Priors: P(class) = {samples in class}/{total samples}\n",
    "2. Compute Mean and Variance (For GaussianNB).\n",
    "3. Apply Bayes' Formula to get posterior probabilities.\n",
    "4. Select Class with Maximum Probability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
